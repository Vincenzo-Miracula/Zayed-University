{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHy301G1T2wD0szMk+ztuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vincenzo-Miracula/Zayed-University/blob/main/Linear_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2XW__P90icj"
      },
      "source": [
        "## Inferential Statistics\n",
        "Use data analysis on a sample of data to infer properties and make predictions that cannot be derived from descriptive statistics. Examples of this could be predicting a new unknown value based on previous data (linear regression, machine learning) or hypothesis testing (such as T-tests)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEwiKOMet3Jj"
      },
      "source": [
        "# Regression in Python\n",
        "\n",
        "***\n",
        "This is a very quick run-through of some basic statistical concepts, adapted from [Lab 4 in Harvard's CS109](https://github.com/cs109/2015lab4) course. Please feel free to try the original lab if you're feeling ambitious :-) The CS109 git repository also has the solutions if you're stuck.\n",
        "\n",
        "* Linear Regression Models\n",
        "* Prediction using linear regression\n",
        "* Some re-sampling methods    \n",
        "    * Train-Test splits\n",
        "    * Cross Validation\n",
        "\n",
        "Linear regression is used to model and predict continuous outcomes while logistic regression is used to model binary outcomes. We'll see some examples of linear regression as well as Train-test splits.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# Part 1: Linear Regression\n",
        "### Purpose of linear regression\n",
        "\n",
        "<p> Given a dataset $X$ and $Y$, linear regression can be used to: </p>\n",
        "<ul>\n",
        "  <li> Build a <b>predictive model</b> to predict future values of $X_i$ without a $Y$ value.  </li>\n",
        "  <li> Model the <b>strength of the relationship</b> between each dependent variable $X_i$ and $Y$</li>\n",
        "    <ul>\n",
        "      <li> Sometimes not all $X_i$ will have a relationship with $Y$</li>\n",
        "      <li> Need to figure out which $X_i$ contributes most information to determine $Y$ </li>\n",
        "    </ul>\n",
        "   <li>Linear regression is used in so many applications that I won't warrant this with examples. It is in many cases, the first pass prediction algorithm for continuous outcomes. </li>\n",
        "</ul>\n",
        "</div>\n",
        "***"
      ],
      "metadata": {
        "id": "_iLlgKDauJRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LDMKOMtyk_UQ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boston House Prices dataset\n",
        "===========================\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506\n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None"
      ],
      "metadata": {
        "id": "mdAdjJC7ueDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", sep='\\s+', names=[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PRATIO\",\"B\",\"LSTAT\",\"MEDV\"])"
      ],
      "metadata": {
        "id": "U-4uzx1clXRI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.head()"
      ],
      "metadata": {
        "id": "ONNT_0za81E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.info()"
      ],
      "metadata": {
        "id": "B4HbBr6F85OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.isna().sum()"
      ],
      "metadata": {
        "id": "8gWhh7JG88kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.describe().T"
      ],
      "metadata": {
        "id": "xnJGdwlj8_qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = boston.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix of Variables in the Boston Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CxaoMzAN1RK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.plot(x=\"RM\", y=\"MEDV\", style=\"o\")\n",
        "plt.xlabel(\"Average number of rooms per dwelling(RM)\")\n",
        "plt.ylabel(\"Housing Price\")\n",
        "plt.title(\"Relationship between RM and Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oMkbE7L0tKc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(y=\"MEDV\", x=\"RM\", data=boston, fit_reg = True)"
      ],
      "metadata": {
        "id": "bUd-5LkBuyGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.plot(x=\"RM\", y=\"CRIM\", style=\"o\")\n",
        "plt.xlabel(\"Average number of rooms per dwelling(RM)\")\n",
        "plt.ylabel(\"Housing Price\")\n",
        "plt.title(\"Relationship between RM and Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QWkShzcw1teV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(y=\"CRIM\", x=\"RM\", data=boston, fit_reg = True)"
      ],
      "metadata": {
        "id": "hDsx7jcs1uwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(boston['RM'])\n",
        "plt.title(\"RM\")\n",
        "plt.xlabel(\"Average number of rooms per dwelling\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2RpK4FN3u_Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(boston[\"MEDV\"])\n",
        "plt.title(\"MEDV\")\n",
        "plt.xlabel(\"Average price of rooms per dwelling\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IqS7OABMvIOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression with  Boston housing data example\n",
        "***\n",
        "\n",
        "Here,\n",
        "\n",
        "$Y$ = boston housing prices (also called \"target\" data in python)\n",
        "\n",
        "and\n",
        "\n",
        "$X$ = all the other features (or independent variables)\n",
        "\n",
        "which we will use to fit a linear regression model and predict Boston housing prices. We will use the least squares method as the way to estimate the coefficients.  "
      ],
      "metadata": {
        "id": "gQeZhSBRvSdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = boston[['RM']] #feature\n",
        "Y = boston[\"MEDV\"] #target"
      ],
      "metadata": {
        "id": "YD53z8OfldkT"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "2PcKXjLtj3aa"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPwfTyLqjwVb"
      },
      "outputs": [],
      "source": [
        "lm = LinearRegression()\n",
        "lm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL2iW7HLt3Ju"
      },
      "source": [
        "#### What can you do with a LinearRegression object?\n",
        "***\n",
        "Check out the scikit-learn [docs here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). We have listed the main functions here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfaa0sT-t3Ju"
      },
      "source": [
        "Main functions | Description\n",
        "--- | ---\n",
        "`lm.fit()` | Fit a linear model\n",
        "`lm.predit()` | Predict Y using the linear model with estimated coefficients\n",
        "`lm.score()` | Returns the coefficient of determination (R^2). *A measure of how well observed outcomes are replicated by the model, as the proportion of total variation of outcomes explained by the model*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_pred = lm.predict(X_test)"
      ],
      "metadata": {
        "id": "Es-MbMfLrROU"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R2 = r2_score(Y_test, Y_test_pred)\n",
        "R2"
      ],
      "metadata": {
        "id": "jILbiXuAxvfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"coefficient of determination:\", lm.score(X, Y))\n",
        "print(\"intercept:\", lm.intercept_)\n",
        "print(\"coefficients:\", lm.coef_)"
      ],
      "metadata": {
        "id": "5GRfaXyoqlAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(lm.predict(X))\n",
        "plt.title(\"PREDICTION PRICE\")\n",
        "plt.xlabel(\"Predicted Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-kaRoNG0vytK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.regplot(x=lm.predict(X), y=boston[\"MEDV\"], data=boston, fit_reg=True)"
      ],
      "metadata": {
        "id": "1IrNV9rzv0yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "CwzZ3g5bwNd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNp_f5iiZEGO"
      },
      "source": [
        "## Logistic Regression\n",
        "A logistic regression models the relationship between a binary output and one (or more) input variables. With one input and one output variable, you're essentially finding the best-fitting curve. Instead of calculating a slope and y-intercept for a line, you're determining coefficients that minimize the difference between the observed and predicted outcomes, typically through a process like maximum likelihood estimation. Once trained, the logistic regression can classify new data points based on their input variables, assigning them to one of two categories."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "yeK8dloR5o3n"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "meQugy1u5Cbg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['species'] = iris.target_names[iris.target]"
      ],
      "metadata": {
        "id": "hSWvw9XI6Z7O"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.head()"
      ],
      "metadata": {
        "id": "iwRyRS8H5zDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.shape"
      ],
      "metadata": {
        "id": "INmNn2q15CvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.info()"
      ],
      "metadata": {
        "id": "jNFm7uNi5EPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.isna().sum()"
      ],
      "metadata": {
        "id": "ZF3yJ0du5FvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.describe().T"
      ],
      "metadata": {
        "id": "6qDoWe1v5HU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df['species'].value_counts()"
      ],
      "metadata": {
        "id": "DXi9_7uv5IUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_palette = {'setosa': 'blue', 'versicolor': 'green', 'virginica': 'orange'}\n",
        "sns.set_style('whitegrid')\n",
        "sns.FacetGrid(iris_df, hue='species', palette=custom_palette, height=5, aspect=1.5) \\\n",
        "    .map(plt.scatter, 'sepal length (cm)', 'sepal width (cm)') \\\n",
        "    .add_legend()\n",
        "plt.title(\"Iris Flower Sepal Length and Sepal width\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xr-8GG195K5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.pairplot(iris_df,hue='species',palette=custom_palette,size=4)\n",
        "plt.title(\"Iris Flower Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aglmkoap5MX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {'setosa' : 0,'versicolor' : 1,'virginica' : 2}\n",
        "iris_df['species'] = iris_df['species'].replace(labels)"
      ],
      "metadata": {
        "id": "HA0OjhsH5SVh"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris_df.drop(columns=['species']) #features\n",
        "y = iris_df['species'] #target variable"
      ],
      "metadata": {
        "id": "sS3H2DX25T2K"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "NKRqg7X23auf"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "NrH-dAjRj3BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_pred = log_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "ebm9UaZU3opo"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R2 = r2_score(Y_test, Y_test_pred)\n",
        "R2"
      ],
      "metadata": {
        "id": "RDiQJ_zH3qhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"coefficient of determination:\", log_reg.score(X, y))\n",
        "print(\"intercept:\", log_reg.intercept_)\n",
        "print(\"coefficients:\", log_reg.coef_)"
      ],
      "metadata": {
        "id": "ArQzmtKq3uDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr = classification_report(Y_test_pred,Y_test)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "z7sJNbNN5cMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_s = accuracy_score(Y_test_pred,Y_test)\n",
        "print(\"Accuracy score of Logistice Regression : %.2f\"%((a_s)*100),'%')"
      ],
      "metadata": {
        "id": "UJdrQDZ05d-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "yGNlzQOo318-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}